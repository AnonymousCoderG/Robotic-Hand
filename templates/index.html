<!DOCTYPE html>
<html>
<head>
    <title>Robotic Hand Control (Async)</title>
    <meta charset="utf-8">
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
    <style>
        body { font-family: sans-serif; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; margin: 0; background-color: #2c3e50; color: white; }
        #output_canvas { border: 5px solid #3498db; border-radius: 10px; background-color: #000; }
        #webcam { display: none; }
        #status { margin-top: 15px; font-size: 1.2em; color: #ecf0f1; }
        #startButton { 
            display: none; /* Hidden by default */
            font-size: 1.5em;
            padding: 10px 20px;
            margin-top: 20px;
            cursor: pointer;
            border-radius: 8px;
            border: 2px solid #3498db;
            background-color: #2980b9;
            color: white;
        }
    </style>
</head>
<body>
    <h1>Robotic Hand Control Stream</h1>
    <canvas id="output_canvas" width="640px" height="480px"></canvas>
    <video id="webcam" autoplay playsinline style="display:none;"></video>
    <p id="status">Status: Initializing...</p>
    <button id="startButton">Start Camera</button>

    <script type="module">
        const videoElement = document.getElementById('webcam');
        const canvasElement = document.getElementById('output_canvas');
        const canvasCtx = canvasElement.getContext('2d');
        const statusElement = document.getElementById('status');
        const startButton = document.getElementById('startButton');

        const tipIds = [4, 8, 12, 16, 20];
        let lastSendTime = 0;
        const SEND_INTERVAL = 250; // Milliseconds

        const worker = new Worker('/static/worker.js');

        worker.onmessage = (event) => {
            const { landmarks, image } = event.data;
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.drawImage(image, 0, 0, canvasElement.width, canvasElement.height);

            if (landmarks && landmarks.length > 0) {
                const handLandmarks = landmarks[0];
                drawConnectors(canvasCtx, handLandmarks, HANDS_CONNECTIONS, { color: '#FFFFFF', lineWidth: 5 });
                drawLandmarks(canvasCtx, handLandmarks, { color: '#FF0000', lineWidth: 2 });
                
                const currentTime = Date.now();
                if (currentTime - lastSendTime > SEND_INTERVAL) {
                    let fingers = [];
                    if (handLandmarks[tipIds[0]].x > handLandmarks[tipIds[0] - 1].x) { fingers.push(1); } else { fingers.push(0); }
                    for (let id = 1; id < 5; id++) {
                        if (handLandmarks[tipIds[id]].y < handLandmarks[tipIds[id] - 2].y) { fingers.push(1); } else { fingers.push(0); }
                    }
                    
                    const angles = { "thumb": fingers[0]===1?90:0, "index": fingers[1]===1?0:90, "middle": fingers[2]===1?0:180, "ring": fingers[3]===1?0:90, "pinky": fingers[4]===1?90:0 };

                    fetch('/api/hand_data', { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(angles) })
                        .then(() => statusElement.textContent = `Status: Command Sent!`);
                    lastSendTime = currentTime;
                }
            } else {
                 statusElement.textContent = "Status: No hand detected.";
            }
            canvasCtx.restore();
        };

        async function processVideo() {
            const imageBitmap = await createImageBitmap(videoElement);
            worker.postMessage(imageBitmap, [imageBitmap]);
            requestAnimationFrame(processVideo);
        }

        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } });
                videoElement.srcObject = stream;
                
                // We must wait for the onplaying event to ensure the video is truly ready.
                videoElement.onplaying = () => {
                    statusElement.textContent = "Status: Camera playing. Show your hand.";
                    startButton.style.display = 'none'; // Hide button if it was shown
                    processVideo(); // Start the main loop
                };
                
                // Try to play the video.
                await videoElement.play();
                console.log("Video autoplay successful.");

            } catch (err) {
                console.error("Video autoplay was prevented: ", err);
                statusElement.textContent = "Click the button to start the camera.";
                // If autoplay fails, show the button for the user to click.
                startButton.style.display = 'block';
            }
        }
        
        // Add a click listener to the button to manually start the video.
        startButton.addEventListener('click', () => {
            statusElement.textContent = "Starting camera after click...";
            videoElement.play();
        });

        startCamera();
    </script>
</body>
</html>