<!DOCTYPE html>
<html>
<head>
    <title>Robotic Hand Control (Async)</title>
    <meta charset="utf-8">
    <!-- We only need drawing utils here now -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
    <style>
        body { font-family: sans-serif; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; margin: 0; background-color: #2c3e50; color: white; }
        #output_canvas { border: 5px solid #3498db; border-radius: 10px; background-color: #000; }
        #webcam { display: none; }
        #status { margin-top: 15px; font-size: 1.2em; color: #ecf0f1; }
    </style>
</head>
<body>
    <h1>Robotic Hand Control Stream</h1>
    <canvas id="output_canvas" width="640px" height="480px"></canvas>
    <video id="webcam" autoplay playsinline style="display:none;"></video>
    <p id="status">Status: Initializing...</p>

    <script type="module">
        const videoElement = document.getElementById('webcam');
        const canvasElement = document.getElementById('output_canvas');
        const canvasCtx = canvasElement.getContext('2d');
        const statusElement = document.getElementById('status');

        const tipIds = [4, 8, 12, 16, 20];
        let lastSendTime = 0;
        const SEND_INTERVAL = 250; // Milliseconds (4 times per second)

        // Create the Web Worker
        const worker = new Worker('/static/worker.js');

        // This function handles messages received FROM the worker
        worker.onmessage = (event) => {
            const { landmarks, image } = event.data;

            // Draw the raw image from the worker onto the canvas
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.drawImage(image, 0, 0, canvasElement.width, canvasElement.height);

            if (landmarks && landmarks.length > 0) {
                const handLandmarks = landmarks[0];
                drawConnectors(canvasCtx, handLandmarks, HANDS_CONNECTIONS, { color: '#FFFFFF', lineWidth: 5 });
                drawLandmarks(canvasCtx, handLandmarks, { color: '#FF0000', lineWidth: 2 });
                
                const currentTime = Date.now();
                if (currentTime - lastSendTime > SEND_INTERVAL) {
                    let fingers = [];
                    if (handLandmarks[tipIds[0]].x > handLandmarks[tipIds[0] - 1].x) { fingers.push(1); } else { fingers.push(0); }
                    for (let id = 1; id < 5; id++) {
                        if (handLandmarks[tipIds[id]].y < handLandmarks[tipIds[id] - 2].y) { fingers.push(1); } else { fingers.push(0); }
                    }
                    
                    const angles = {
                        "thumb": fingers[0] === 1 ? 90 : 0,
                        "index": fingers[1] === 1 ? 0 : 90,
                        "middle": fingers[2] === 1 ? 0 : 180,
                        "ring": fingers[3] === 1 ? 0 : 90,
                        "pinky": fingers[4] === 1 ? 90 : 0
                    };

                    // Send the data to our Flask server
                    fetch('/api/hand_data', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(angles)
                    }).then(() => statusElement.textContent = `Status: Command Sent!`);
                    lastSendTime = currentTime;
                }
            } else {
                 statusElement.textContent = "Status: No hand detected.";
            }
            canvasCtx.restore();
        };

        // This function sends video frames TO the worker
        async function processVideo() {
            // Get the current video frame as an ImageData object
            canvasCtx.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);
            const imageData = canvasCtx.getImageData(0, 0, canvasElement.width, canvasElement.height);

            // Post the image data to the worker to be processed
            worker.postMessage(imageData);

            // Request the next animation frame to continue the loop
            requestAnimationFrame(processVideo);
        }

        // Start the camera
        navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } })
            .then(stream => {
                videoElement.srcObject = stream;
                videoElement.addEventListener('loadeddata', processVideo);
                statusElement.textContent = "Status: Camera started. Show your hand.";
            })
            .catch(err => {
                console.error("Error accessing camera: ", err);
                statusElement.textContent = "Error: Could not access camera.";
            });
    </script>
</body>
</html>